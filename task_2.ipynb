{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "U80GsH6hOiM1"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = \"/content/instric.zip\"  # Replace with your ZIP filename\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"unzipped_folder\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/unzipped_folder/instric/src')\n"
      ],
      "metadata": {
        "id": "cYvVg0rQb1Z8"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/src/train.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiw19_rlbO8a",
        "outputId": "b1894598-c117-4d16-f882-b98aba539349"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing normalization stats from training data...\n",
            "Stats computed and saved (mean=0.4998, std=0.2887).\n",
            "Loaded normalization stats (mean=0.4998, std=0.2887).\n",
            "Starting Triplet Loss training on cuda...\n",
            "Epoch [1/100], Train Loss: 1.0085, Val Loss: 1.0021\n",
            " ⭐ New best model saved with validation loss: 1.0021\n",
            "Epoch [2/100], Train Loss: 1.0007, Val Loss: 1.0017\n",
            " ⭐ New best model saved with validation loss: 1.0017\n",
            "Epoch [3/100], Train Loss: 1.0083, Val Loss: 1.0021\n",
            "Epoch [4/100], Train Loss: 0.9963, Val Loss: 1.0017\n",
            "Epoch [5/100], Train Loss: 1.0000, Val Loss: 1.0014\n",
            " ⭐ New best model saved with validation loss: 1.0014\n",
            "Epoch [6/100], Train Loss: 1.0038, Val Loss: 0.9999\n",
            " ⭐ New best model saved with validation loss: 0.9999\n",
            "Epoch [7/100], Train Loss: 0.9964, Val Loss: 0.9994\n",
            " ⭐ New best model saved with validation loss: 0.9994\n",
            "Epoch [8/100], Train Loss: 0.9934, Val Loss: 1.0011\n",
            "Epoch [9/100], Train Loss: 0.9914, Val Loss: 1.0002\n",
            "Epoch [10/100], Train Loss: 0.9969, Val Loss: 0.9993\n",
            " ⭐ New best model saved with validation loss: 0.9993\n",
            "Epoch [11/100], Train Loss: 0.9935, Val Loss: 1.0007\n",
            "Epoch [12/100], Train Loss: 0.9962, Val Loss: 0.9994\n",
            "Epoch [13/100], Train Loss: 0.9993, Val Loss: 1.0006\n",
            "Epoch [14/100], Train Loss: 1.0073, Val Loss: 1.0001\n",
            "Epoch [15/100], Train Loss: 0.9980, Val Loss: 0.9992\n",
            " ⭐ New best model saved with validation loss: 0.9992\n",
            "Epoch [16/100], Train Loss: 0.9951, Val Loss: 1.0012\n",
            "Epoch [17/100], Train Loss: 1.0121, Val Loss: 1.0021\n",
            "Epoch [18/100], Train Loss: 1.0099, Val Loss: 0.9999\n",
            "Epoch [19/100], Train Loss: 1.0017, Val Loss: 1.0016\n",
            "Epoch [20/100], Train Loss: 0.9944, Val Loss: 1.0004\n",
            "Epoch [21/100], Train Loss: 1.0076, Val Loss: 0.9997\n",
            "Epoch [22/100], Train Loss: 1.0047, Val Loss: 1.0012\n",
            "Epoch [23/100], Train Loss: 1.0084, Val Loss: 1.0018\n",
            "Epoch [24/100], Train Loss: 0.9886, Val Loss: 0.9992\n",
            " ⭐ New best model saved with validation loss: 0.9992\n",
            "Epoch [25/100], Train Loss: 1.0047, Val Loss: 1.0001\n",
            "Epoch [26/100], Train Loss: 1.0111, Val Loss: 0.9995\n",
            "Epoch [27/100], Train Loss: 0.9912, Val Loss: 0.9999\n",
            "Epoch [28/100], Train Loss: 1.0070, Val Loss: 1.0000\n",
            "Epoch [29/100], Train Loss: 0.9987, Val Loss: 1.0000\n",
            "Epoch [30/100], Train Loss: 1.0029, Val Loss: 0.9999\n",
            "Epoch [31/100], Train Loss: 1.0112, Val Loss: 1.0000\n",
            "Epoch [32/100], Train Loss: 0.9941, Val Loss: 1.0005\n",
            "Epoch [33/100], Train Loss: 1.0070, Val Loss: 0.9999\n",
            "Epoch [34/100], Train Loss: 1.0039, Val Loss: 0.9992\n",
            " ⭐ New best model saved with validation loss: 0.9992\n",
            "Epoch [35/100], Train Loss: 0.9992, Val Loss: 1.0002\n",
            "Epoch [36/100], Train Loss: 1.0075, Val Loss: 1.0004\n",
            "Epoch [37/100], Train Loss: 0.9985, Val Loss: 1.0006\n",
            "Epoch [38/100], Train Loss: 0.9961, Val Loss: 1.0007\n",
            "Epoch [39/100], Train Loss: 1.0098, Val Loss: 1.0000\n",
            "Epoch [40/100], Train Loss: 1.0040, Val Loss: 0.9990\n",
            " ⭐ New best model saved with validation loss: 0.9990\n",
            "Epoch [41/100], Train Loss: 1.0001, Val Loss: 1.0005\n",
            "Epoch [42/100], Train Loss: 0.9924, Val Loss: 1.0000\n",
            "Epoch [43/100], Train Loss: 1.0005, Val Loss: 1.0002\n",
            "Epoch [44/100], Train Loss: 0.9973, Val Loss: 1.0001\n",
            "Epoch [45/100], Train Loss: 0.9952, Val Loss: 0.9998\n",
            "Epoch [46/100], Train Loss: 1.0004, Val Loss: 0.9997\n",
            "Epoch [47/100], Train Loss: 1.0061, Val Loss: 0.9996\n",
            "Epoch [48/100], Train Loss: 0.9841, Val Loss: 0.9992\n",
            "Epoch [49/100], Train Loss: 0.9969, Val Loss: 1.0002\n",
            "Epoch [50/100], Train Loss: 1.0051, Val Loss: 1.0003\n",
            "Epoch [51/100], Train Loss: 1.0047, Val Loss: 1.0002\n",
            "Epoch [52/100], Train Loss: 0.9939, Val Loss: 0.9997\n",
            "Epoch [53/100], Train Loss: 0.9979, Val Loss: 1.0004\n",
            "Epoch [54/100], Train Loss: 1.0001, Val Loss: 1.0004\n",
            "Epoch [55/100], Train Loss: 1.0131, Val Loss: 1.0005\n",
            "Epoch [56/100], Train Loss: 0.9978, Val Loss: 1.0005\n",
            "Epoch [57/100], Train Loss: 1.0011, Val Loss: 1.0003\n",
            "Epoch [58/100], Train Loss: 1.0047, Val Loss: 1.0002\n",
            "Epoch [59/100], Train Loss: 1.0049, Val Loss: 1.0000\n",
            "Epoch [60/100], Train Loss: 1.0014, Val Loss: 0.9993\n",
            "Epoch [61/100], Train Loss: 1.0094, Val Loss: 1.0001\n",
            "Epoch [62/100], Train Loss: 0.9880, Val Loss: 0.9999\n",
            "Epoch [63/100], Train Loss: 1.0090, Val Loss: 1.0001\n",
            "Epoch [64/100], Train Loss: 0.9928, Val Loss: 0.9997\n",
            "Epoch [65/100], Train Loss: 1.0093, Val Loss: 1.0003\n",
            "Epoch [66/100], Train Loss: 1.0000, Val Loss: 1.0001\n",
            "Epoch [67/100], Train Loss: 1.0075, Val Loss: 0.9997\n",
            "Epoch [68/100], Train Loss: 0.9943, Val Loss: 0.9999\n",
            "Epoch [69/100], Train Loss: 1.0226, Val Loss: 1.0003\n",
            "Epoch [70/100], Train Loss: 0.9914, Val Loss: 1.0007\n",
            "Epoch [71/100], Train Loss: 0.9942, Val Loss: 0.9998\n",
            "Epoch [72/100], Train Loss: 0.9958, Val Loss: 1.0012\n",
            "Epoch [73/100], Train Loss: 0.9907, Val Loss: 1.0000\n",
            "Epoch [74/100], Train Loss: 1.0138, Val Loss: 0.9996\n",
            "Epoch [75/100], Train Loss: 0.9978, Val Loss: 1.0004\n",
            "Epoch [76/100], Train Loss: 0.9999, Val Loss: 1.0005\n",
            "Epoch [77/100], Train Loss: 0.9738, Val Loss: 1.0010\n",
            "Epoch [78/100], Train Loss: 0.9909, Val Loss: 1.0002\n",
            "Epoch [79/100], Train Loss: 0.9846, Val Loss: 1.0006\n",
            "Epoch [80/100], Train Loss: 0.9926, Val Loss: 1.0001\n",
            "Epoch [81/100], Train Loss: 0.9996, Val Loss: 1.0005\n",
            "Epoch [82/100], Train Loss: 1.0208, Val Loss: 1.0004\n",
            "Epoch [83/100], Train Loss: 0.9960, Val Loss: 1.0006\n",
            "Epoch [84/100], Train Loss: 1.0012, Val Loss: 1.0001\n",
            "Epoch [85/100], Train Loss: 0.9786, Val Loss: 0.9997\n",
            "Epoch [86/100], Train Loss: 1.0062, Val Loss: 1.0003\n",
            "Epoch [87/100], Train Loss: 0.9866, Val Loss: 1.0008\n",
            "Epoch [88/100], Train Loss: 1.0087, Val Loss: 1.0007\n",
            "Epoch [89/100], Train Loss: 0.9972, Val Loss: 1.0000\n",
            "Epoch [90/100], Train Loss: 0.9647, Val Loss: 1.0003\n",
            "Epoch [91/100], Train Loss: 1.0003, Val Loss: 1.0010\n",
            "Epoch [92/100], Train Loss: 1.0045, Val Loss: 0.9998\n",
            "Epoch [93/100], Train Loss: 1.0312, Val Loss: 1.0010\n",
            "Epoch [94/100], Train Loss: 0.9928, Val Loss: 0.9999\n",
            "Epoch [95/100], Train Loss: 0.9808, Val Loss: 1.0003\n",
            "Epoch [96/100], Train Loss: 1.0195, Val Loss: 0.9993\n",
            "Epoch [97/100], Train Loss: 0.9936, Val Loss: 1.0003\n",
            "Epoch [98/100], Train Loss: 1.0104, Val Loss: 1.0006\n",
            "Epoch [99/100], Train Loss: 0.9756, Val Loss: 1.0005\n",
            "Epoch [100/100], Train Loss: 1.0037, Val Loss: 0.9996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/src/train_decoder.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOr2yEbr1Lt6",
        "outputId": "541bc277-b07b-4ba1-f35e-3d83aefe08b0"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading pre-trained speaker encoder from speaker_encoder_triplet_best.pth\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "Starting unified training on cuda with ResNet Decoder and L1 Loss...\n",
            "\n",
            "Epoch [1/200] Current LRs: Encoder=5.00e-07, Decoder=2.00e-05\n",
            "Train Loss: 2.0656, Val Loss: 1.8704\n",
            "Validation loss decreased (inf --> 1.870387).  Saving model ...\n",
            "\n",
            "Epoch [2/200] Current LRs: Encoder=1.00e-06, Decoder=4.00e-05\n",
            "Train Loss: 1.9563, Val Loss: 1.8720\n",
            "EarlyStopping counter: 1 out of 25\n",
            "\n",
            "Epoch [3/200] Current LRs: Encoder=1.50e-06, Decoder=6.00e-05\n",
            "Train Loss: 1.8125, Val Loss: 1.8723\n",
            "EarlyStopping counter: 2 out of 25\n",
            "\n",
            "Epoch [4/200] Current LRs: Encoder=2.00e-06, Decoder=8.00e-05\n",
            "Train Loss: 1.7065, Val Loss: 1.8706\n",
            "EarlyStopping counter: 3 out of 25\n",
            "\n",
            "Epoch [5/200] Current LRs: Encoder=2.50e-06, Decoder=1.00e-04\n",
            "Train Loss: 1.5867, Val Loss: 1.8675\n",
            "Validation loss decreased (1.870387 --> 1.867456).  Saving model ...\n",
            "\n",
            "Epoch [6/200] Current LRs: Encoder=3.00e-06, Decoder=1.20e-04\n",
            "Train Loss: 1.5511, Val Loss: 1.8714\n",
            "EarlyStopping counter: 1 out of 25\n",
            "\n",
            "Epoch [7/200] Current LRs: Encoder=3.50e-06, Decoder=1.40e-04\n",
            "Train Loss: 1.4948, Val Loss: 1.8966\n",
            "EarlyStopping counter: 2 out of 25\n",
            "\n",
            "Epoch [8/200] Current LRs: Encoder=4.00e-06, Decoder=1.60e-04\n",
            "Train Loss: 1.4668, Val Loss: 1.9771\n",
            "EarlyStopping counter: 3 out of 25\n",
            "\n",
            "Epoch [9/200] Current LRs: Encoder=4.50e-06, Decoder=1.80e-04\n",
            "Train Loss: 1.4478, Val Loss: 2.0786\n",
            "EarlyStopping counter: 4 out of 25\n",
            "\n",
            "Epoch [10/200] Current LRs: Encoder=5.00e-06, Decoder=2.00e-04\n",
            "Train Loss: 1.3940, Val Loss: 2.3033\n",
            "EarlyStopping counter: 5 out of 25\n",
            "\n",
            "Epoch [11/200] Current LRs: Encoder=5.00e-06, Decoder=2.00e-04\n",
            "Train Loss: 1.3852, Val Loss: 2.1280\n",
            "EarlyStopping counter: 6 out of 25\n",
            "\n",
            "Epoch [12/200] Current LRs: Encoder=5.00e-06, Decoder=2.00e-04\n",
            "Train Loss: 1.3904, Val Loss: 2.2808\n",
            "EarlyStopping counter: 7 out of 25\n",
            "\n",
            "Epoch [13/200] Current LRs: Encoder=5.00e-06, Decoder=2.00e-04\n",
            "Train Loss: 1.3838, Val Loss: 2.1729\n",
            "EarlyStopping counter: 8 out of 25\n",
            "\n",
            "Epoch [14/200] Current LRs: Encoder=5.00e-06, Decoder=2.00e-04\n",
            "Train Loss: 1.3771, Val Loss: 2.3024\n",
            "EarlyStopping counter: 9 out of 25\n",
            "\n",
            "Epoch [15/200] Current LRs: Encoder=5.00e-06, Decoder=2.00e-04\n",
            "Train Loss: 1.3639, Val Loss: 2.1394\n",
            "EarlyStopping counter: 10 out of 25\n",
            "\n",
            "Epoch [16/200] Current LRs: Encoder=5.00e-06, Decoder=2.00e-04\n",
            "Train Loss: 1.2806, Val Loss: 2.0055\n",
            "EarlyStopping counter: 11 out of 25\n",
            "\n",
            "Epoch [17/200] Current LRs: Encoder=5.00e-06, Decoder=2.00e-04\n",
            "Train Loss: 1.2849, Val Loss: 1.9951\n",
            "EarlyStopping counter: 12 out of 25\n",
            "\n",
            "Epoch [18/200] Current LRs: Encoder=5.00e-06, Decoder=2.00e-04\n",
            "Train Loss: 1.2220, Val Loss: 1.9732\n",
            "EarlyStopping counter: 13 out of 25\n",
            "\n",
            "Epoch [19/200] Current LRs: Encoder=5.00e-06, Decoder=2.00e-04\n",
            "Train Loss: 1.2331, Val Loss: 1.9473\n",
            "EarlyStopping counter: 14 out of 25\n",
            "\n",
            "Epoch [20/200] Current LRs: Encoder=5.00e-06, Decoder=2.00e-04\n",
            "Train Loss: 1.2565, Val Loss: 1.8973\n",
            "EarlyStopping counter: 15 out of 25\n",
            "\n",
            "Epoch [21/200] Current LRs: Encoder=5.00e-06, Decoder=2.00e-04\n",
            "Train Loss: 1.2197, Val Loss: 1.8825\n",
            "EarlyStopping counter: 16 out of 25\n",
            "\n",
            "Epoch [22/200] Current LRs: Encoder=5.00e-06, Decoder=2.00e-04\n",
            "Train Loss: 1.1939, Val Loss: 1.8822\n",
            "EarlyStopping counter: 17 out of 25\n",
            "\n",
            "Epoch [23/200] Current LRs: Encoder=5.00e-06, Decoder=2.00e-04\n",
            "Train Loss: 1.1934, Val Loss: 1.8842\n",
            "EarlyStopping counter: 18 out of 25\n",
            "\n",
            "Epoch [24/200] Current LRs: Encoder=5.00e-06, Decoder=2.00e-04\n",
            "Train Loss: 1.1515, Val Loss: 1.8975\n",
            "EarlyStopping counter: 19 out of 25\n",
            "\n",
            "Epoch [25/200] Current LRs: Encoder=5.00e-06, Decoder=2.00e-04\n",
            "Train Loss: 1.1570, Val Loss: 1.8898\n",
            "EarlyStopping counter: 20 out of 25\n",
            "\n",
            "Epoch [26/200] Current LRs: Encoder=5.00e-06, Decoder=2.00e-04\n",
            "Train Loss: 1.1782, Val Loss: 1.8871\n",
            "EarlyStopping counter: 21 out of 25\n",
            "\n",
            "Epoch [27/200] Current LRs: Encoder=5.00e-06, Decoder=2.00e-04\n",
            "Train Loss: 1.1723, Val Loss: 1.8760\n",
            "EarlyStopping counter: 22 out of 25\n",
            "\n",
            "Epoch [28/200] Current LRs: Encoder=5.00e-06, Decoder=2.00e-04\n",
            "Train Loss: 1.1680, Val Loss: 1.8807\n",
            "EarlyStopping counter: 23 out of 25\n",
            "\n",
            "Epoch [29/200] Current LRs: Encoder=5.00e-06, Decoder=2.00e-04\n",
            "Train Loss: 1.1723, Val Loss: 1.8787\n",
            "EarlyStopping counter: 24 out of 25\n",
            "\n",
            "Epoch [30/200] Current LRs: Encoder=5.00e-06, Decoder=2.00e-04\n",
            "Train Loss: 1.1647, Val Loss: 1.8774\n",
            "EarlyStopping counter: 25 out of 25\n",
            "Early stopping triggered\n",
            "\n",
            "Training finished. Best model saved to voice_cloning_model_best.pth with validation loss: 1.8675\n",
            "Training curve saved to training_curve.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/src/infer.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYhdK5cSFqhv",
        "outputId": "6697205f-84b5-469e-b32a-626bccafe72b"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from voice_cloning_model_best.pth\n",
            "Model loaded successfully.\n",
            "Loaded normalization stats (mean=0.4998, std=0.2887).\n",
            "Loaded 5 reference utterances.\n",
            "Cloned voice for speaker 0.\n",
            "Cloned voice for speaker 1.\n",
            "Cloned voice for speaker 2.\n",
            "Cloned voice for speaker 3.\n",
            "Cloned voice for speaker 4.\n",
            "Successfully saved 5 predictions to cloned_mel_predictions.csv\n"
          ]
        }
      ]
    }
  ]
}